{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9d4e98",
   "metadata": {},
   "source": [
    "**Método de Filtrado**:\n",
    "\n",
    "El método de filtrado utiliza medidas estadísticas para asignar un puntaje a cada característica. Las características con puntajes más altos se consideran más relevantes y se seleccionan para el modelo. SelectKBest de sklearn.feature_selection es un ejemplo de un método de filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5734fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas usando método de Filtro:\n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Seleccionar las 2 mejores características usando ANOVA-F como métrica de evaluación\n",
    "selector_filtro = SelectKBest(score_func=f_classif, k=2)\n",
    "X_filtrado = selector_filtro.fit_transform(X, y)\n",
    "\n",
    "print(\"Características seleccionadas usando método de Filtro:\")\n",
    "print(X_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cab04",
   "metadata": {},
   "source": [
    "En este ejemplo, SelectKBest utiliza el método de ANOVA-F para seleccionar las 2 mejores características del conjunto de datos Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db474aa",
   "metadata": {},
   "source": [
    "**Método \"Wrapper\":**\n",
    "    \n",
    "Los métodos \"wrapper\" envuelven el modelo de aprendizaje automático y evalúan diferentes combinaciones de características para determinar cuál conjunto proporciona el mejor rendimiento del modelo. RFE (Recursive Feature Elimination) de sklearn.feature_selection es un ejemplo de un método \"wrapper\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e06923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas usando método Wrapper (RFE):\n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JORGE LUIS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Crear un modelo de clasificación\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Seleccionar las 2 mejores características usando RFE (Recursive Feature Elimination)\n",
    "selector_wrapper = RFE(estimator=modelo, n_features_to_select=2)\n",
    "X_wrapper = selector_wrapper.fit_transform(X, y)\n",
    "\n",
    "print(\"Características seleccionadas usando método Wrapper (RFE):\")\n",
    "print(X_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78120160",
   "metadata": {},
   "source": [
    "En este ejemplo, RFE utiliza regresión logística como estimador para seleccionar las 2 mejores características del conjunto de datos Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91e758",
   "metadata": {},
   "source": [
    "**Método Embebido:** \n",
    "\n",
    "El método embebido implica que el proceso de selección de características está incorporado en el propio proceso de entrenamiento del modelo. Veamos un ejemplo utilizando RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962acb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancias de características usando método Embebido:\n",
      "[0.10612762 0.02167809 0.43612951 0.43606478]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Crear un modelo de clasificación con Random Forest (que realiza selección de características automáticamente)\n",
    "modelo_embebido = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_embebido.fit(X, y)\n",
    "\n",
    "# Obtener importancias de características\n",
    "importancias_caracteristicas = modelo_embebido.feature_importances_\n",
    "\n",
    "print(\"Importancias de características usando método Embebido:\")\n",
    "print(importancias_caracteristicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3e030",
   "metadata": {},
   "source": [
    "En resumen, estos son ejemplos básicos para ilustrar cómo funcionan estos métodos. En la práctica, es importante considerar las características específicas del conjunto de datos y el problema que estás abordando para elegir el método de selección de características más adecuado. Además, siempre es crucial evaluar el rendimiento del modelo después de aplicar la selección de características para asegurarse de que mejore la calidad del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
